{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-04T16:31:13.986637Z",
     "start_time": "2025-12-04T16:31:04.603076Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\srbuh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data Preprocessing",
   "id": "419e0ddfbf925344"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:31:20.936553Z",
     "start_time": "2025-12-04T16:31:14.019357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "brown_sentences = list(brown.sents())\n",
    "print(f\" Count of sentences: {len(brown_sentences)}\")\n",
    "print(f\"First sentence: {brown_sentences[0]}\")"
   ],
   "id": "cc387e8f8238aa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count of sentences: 57340\n",
      "First sentence: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:31:21.523471Z",
     "start_time": "2025-12-04T16:31:21.517851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_sentences = [\n",
    "    # Group 1: Morphologically Related Words\n",
    "    \"the teacher is teaching students about grammar\".split(),\n",
    "    \"she teaches mathematics at the university\".split(),\n",
    "    \"the teacher prepared teaching materials yesterday\".split(),\n",
    "    \"many teachers attend teaching conferences annually\".split(),\n",
    "    \"effective teaching requires good communication skills\".split(),\n",
    "\n",
    "    # Group 2: Rare Morphological Variant (appears only once)\n",
    "    \"the unteachable student refused to learn\".split(),\n",
    "\n",
    "    # Group 3: Compound and Derived Words\n",
    "    \"computational linguistics combines computer science and language\".split(),\n",
    "    \"the computation took several hours to complete\".split(),\n",
    "    \"we computed the results using advanced algorithms\".split(),\n",
    "    \"modern computers can compute complex calculations quickly\".split(),\n",
    "\n",
    "    # Group 4: Rare Compound (appears only once)\n",
    "    \"the recomputation was necessary after finding errors\".split(),\n",
    "\n",
    "    # Group 5: Another Morphological Family\n",
    "    \"natural language processing is fascinating\".split(),\n",
    "    \"the nature of language is complex\".split(),\n",
    "    \"naturally occurring patterns in text are important\".split(),\n",
    "\n",
    "    # Group 6: Rare Morphological Variant (appears only once)\n",
    "    \"the unnaturalness of the translation was obvious\".split()\n",
    "]\n",
    "\n",
    "# Combine Brown corpus with test sentences\n",
    "all_sentences = brown_sentences + test_sentences\n",
    "print(f\"\\n✓ Count of all sentences: {len(all_sentences)}\")"
   ],
   "id": "227812c1548fe2b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Count of all sentences: 57355\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Word2Vec Training",
   "id": "cae88b93f01ecdf0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:32:02.745343Z",
     "start_time": "2025-12-04T16:31:21.551875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=all_sentences,\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    sg=1,\n",
    "    epochs=20,\n",
    "    workers=4,\n",
    ")\n",
    "\n",
    "print(f\"Model's statistics:\")\n",
    "print(f\"Vocabulary Size: {len(word2vec_model.wv)}\")\n",
    "print(f\"Vector size: {word2vec_model.vector_size}\")\n",
    "\n",
    "print(f\"Some words from Vocabulary\")\n",
    "vocab_words = list(word2vec_model.wv.index_to_key)[:10]\n",
    "for word in vocab_words:\n",
    "    print(f\"  - {word}\")\n",
    "\n",
    "test_words = ['teacher', 'teaching', 'teaches', 'unteachable',\n",
    "              'computation', 'computed', 'recomputation',\n",
    "              'natural', 'naturally', 'unnaturalness']\n",
    "\n",
    "for word in test_words:\n",
    "    if word in word2vec_model.wv:\n",
    "        print(f\"  ✓ {word}\")\n",
    "    else:\n",
    "        print(f\" x {word}\")\n",
    "\n",
    "model_filename = \"word2vec_brown.model\"\n",
    "word2vec_model.save(model_filename)\n",
    "print(f\"✓ Model saved as '{model_filename}'\")\n"
   ],
   "id": "724892388d5a7566",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's statistics:\n",
      "Vocabulary Size: 56060\n",
      "Vector size: 300\n",
      "Some words from Vocabulary\n",
      "  - the\n",
      "  - ,\n",
      "  - .\n",
      "  - of\n",
      "  - and\n",
      "  - to\n",
      "  - a\n",
      "  - in\n",
      "  - that\n",
      "  - is\n",
      "  ✓ teacher\n",
      "  ✓ teaching\n",
      "  ✓ teaches\n",
      "  ✓ unteachable\n",
      "  ✓ computation\n",
      "  ✓ computed\n",
      "  ✓ recomputation\n",
      "  ✓ natural\n",
      "  ✓ naturally\n",
      "  ✓ unnaturalness\n",
      "✓ Model saved as 'word2vec_brown.model'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "FastText Training",
   "id": "c15260090fcc119b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:33:39.796819Z",
     "start_time": "2025-12-04T16:32:02.762586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "fasttext_model = FastText(\n",
    "    sentences=all_sentences,\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    sg=1,\n",
    "    epochs=20,\n",
    "    min_n=3,\n",
    "    max_n=6,\n",
    "    workers=4,\n",
    ")\n",
    "\n",
    "print(f\"\\nModel's statistics:\")\n",
    "print(f\" Vocabulary size: {len(fasttext_model.wv)} word\")\n",
    "print(f\" Vector size: {fasttext_model.wv.vector_size}\")\n",
    "\n",
    "print(f\"\\nSome words from Vocabulary:\")\n",
    "vocab_words = list(fasttext_model.wv.index_to_key)[:10]\n",
    "for word in vocab_words:\n",
    "    print(f\"  - {word}\")\n",
    "\n",
    "test_words = ['teacher', 'teaching', 'teaches', 'unteachable',\n",
    "              'computation', 'computed', 'recomputation',\n",
    "              'natural', 'naturally', 'unnaturalness']\n",
    "\n",
    "for word in test_words:\n",
    "    if word in fasttext_model.wv:\n",
    "        print(f\"  ✓ '{word}'\")\n",
    "    else:\n",
    "        print(f\"  ✗ '{word}'\")\n",
    "\n",
    "model_filename = \"fasttext_brown.model\"\n",
    "fasttext_model.save(model_filename)\n",
    "print(f\"✓ Model saved as '{model_filename}'\")"
   ],
   "id": "7758dc9458ee0295",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model's statistics:\n",
      " Vocabulary size: 56060 word\n",
      " Vector size: 300\n",
      "\n",
      "Some words from Vocabulary:\n",
      "  - the\n",
      "  - ,\n",
      "  - .\n",
      "  - of\n",
      "  - and\n",
      "  - to\n",
      "  - a\n",
      "  - in\n",
      "  - that\n",
      "  - is\n",
      "  ✓ 'teacher'\n",
      "  ✓ 'teaching'\n",
      "  ✓ 'teaches'\n",
      "  ✓ 'unteachable'\n",
      "  ✓ 'computation'\n",
      "  ✓ 'computed'\n",
      "  ✓ 'recomputation'\n",
      "  ✓ 'natural'\n",
      "  ✓ 'naturally'\n",
      "  ✓ 'unnaturalness'\n",
      "✓ Model saved as 'fasttext_brown.model'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1․ Out Of Vocabulary",
   "id": "4d313cda8082f64e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:33:40.491528Z",
     "start_time": "2025-12-04T16:33:40.429631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "oov_words = [\n",
    "    'teachable',      # Related to: teacher, teaching, teaches\n",
    "    'unteacher',      # Made-up word, morphologically related\n",
    "    'supercomputer',  # Related to: computer, compute\n",
    "    'miscomputation', # Related to: computation, compute\n",
    "    'unnaturally'     # Related to: natural, naturally\n",
    "]\n",
    "\n",
    "for word in oov_words:\n",
    "    print(f\"  • {word}\")\n",
    "\n",
    "# Check if these words are in the vocabulary\n",
    "for word in oov_words:\n",
    "    in_w2v = word in word2vec_model.wv\n",
    "    in_ft = word in fasttext_model.wv\n",
    "    print(f\"\\n'{word}':\")\n",
    "    print(f\"  in Word2Vec vocabulary:  {'✓ yes ' if in_w2v else '✗ no'}\")\n",
    "    print(f\"  in FastText vocabulary:  {'✓ yes' if in_ft else '✗ no'}\")\n",
    "\n",
    "# Test getting vectors from Word2Vec\n",
    "print(\"\\n\\n Vectors from Word2Vec:\")\n",
    "print(\"━\"*70)\n",
    "\n",
    "word2vec_results = {}\n",
    "for word in oov_words:\n",
    "    try:\n",
    "        vector = word2vec_model.wv[word]\n",
    "        print(f\"✓ '{word}': Vector`  (size: {len(vector)})\")\n",
    "        word2vec_results[word] = \"success\"\n",
    "    except KeyError:\n",
    "        print(f\"✗ '{word}': KeyError - word is not found in vocabulary\")\n",
    "        word2vec_results[word] = \"failed\"\n",
    "\n",
    "# Test getting vectors from FastText\n",
    "print(\"\\n\\n Vectors from FastText:\")\n",
    "print(\"━\"*70)\n",
    "\n",
    "fasttext_results = {}\n",
    "for word in oov_words:\n",
    "    try:\n",
    "        vector = fasttext_model.wv[word]\n",
    "        print(f\"✓ '{word}': vector created (size: {len(vector)})\")\n",
    "        fasttext_results[word] = \"success\"\n",
    "\n",
    "        # Show the vector's first 5 values as example\n",
    "        print(f\" 1st 5 values of vector: {vector[:5]}\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"✗ '{word}': KeyError - word is not processed\")\n",
    "        fasttext_results[word] = \"failed\""
   ],
   "id": "b775a8572bb6617c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  • teachable\n",
      "  • unteacher\n",
      "  • supercomputer\n",
      "  • miscomputation\n",
      "  • unnaturally\n",
      "\n",
      "'teachable':\n",
      "  in Word2Vec vocabulary:  ✗ no\n",
      "  in FastText vocabulary:  ✓ yes\n",
      "\n",
      "'unteacher':\n",
      "  in Word2Vec vocabulary:  ✗ no\n",
      "  in FastText vocabulary:  ✓ yes\n",
      "\n",
      "'supercomputer':\n",
      "  in Word2Vec vocabulary:  ✗ no\n",
      "  in FastText vocabulary:  ✓ yes\n",
      "\n",
      "'miscomputation':\n",
      "  in Word2Vec vocabulary:  ✗ no\n",
      "  in FastText vocabulary:  ✓ yes\n",
      "\n",
      "'unnaturally':\n",
      "  in Word2Vec vocabulary:  ✓ yes \n",
      "  in FastText vocabulary:  ✓ yes\n",
      "\n",
      "\n",
      " Vectors from Word2Vec:\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "✗ 'teachable': KeyError - word is not found in vocabulary\n",
      "✗ 'unteacher': KeyError - word is not found in vocabulary\n",
      "✗ 'supercomputer': KeyError - word is not found in vocabulary\n",
      "✗ 'miscomputation': KeyError - word is not found in vocabulary\n",
      "✓ 'unnaturally': Vector`  (size: 300)\n",
      "\n",
      "\n",
      " Vectors from FastText:\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "✓ 'teachable': vector created (size: 300)\n",
      " 1st 5 values of vector: [-0.04850154  0.28772223 -0.46258652 -0.70523345 -0.15487394]\n",
      "✓ 'unteacher': vector created (size: 300)\n",
      " 1st 5 values of vector: [ 0.17248423  0.11978691 -0.7378134  -0.10445364 -0.10180014]\n",
      "✓ 'supercomputer': vector created (size: 300)\n",
      " 1st 5 values of vector: [ 0.08135998  0.19488712 -0.18182637 -0.0591195  -0.15573587]\n",
      "✓ 'miscomputation': vector created (size: 300)\n",
      " 1st 5 values of vector: [-0.07582679  0.06180577 -0.167419   -0.2607348  -0.06736865]\n",
      "✓ 'unnaturally': vector created (size: 300)\n",
      " 1st 5 values of vector: [ 0.277762    0.23719668 -0.58209753 -0.42294908  0.28820089]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:33:40.544912Z",
     "start_time": "2025-12-04T16:33:40.533208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Summary comparison\n",
    "print(f\"{'Word':<20} {'Word2Vec':<15} {'FastText':<15}\")\n",
    "print(\"━\"*70)\n",
    "\n",
    "for word in oov_words:\n",
    "    w2v_status = \"✓ \" if word2vec_results[word] == \"success\" else \"✗ \"\n",
    "    ft_status = \"✓ \" if fasttext_results[word] == \"success\" else \"✗ \"\n",
    "    print(f\"{word:<20} {w2v_status:<15} {ft_status:<15}\")\n",
    "\n",
    "# Count successes\n",
    "w2v_success = sum(1 for v in word2vec_results.values() if v == \"success\")\n",
    "ft_success = sum(1 for v in fasttext_results.values() if v == \"success\")\n",
    "\n",
    "print(\"━\"*70)\n",
    "print(f\"{'All:':<20} {w2v_success}/{len(oov_words):<15} {ft_success}/{len(oov_words):<15}\")\n",
    "print(\"━\"*70)\n"
   ],
   "id": "402407aaebc76754",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                 Word2Vec        FastText       \n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "teachable            ✗               ✓              \n",
      "unteacher            ✗               ✓              \n",
      "supercomputer        ✗               ✓              \n",
      "miscomputation       ✗               ✓              \n",
      "unnaturally          ✓               ✓              \n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "All:                 1/5               5/5              \n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1․ Which model can handle OOV words? Explain the mechanism.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "FastText can create a vector for OOV (out-of-vocabulary) words, while Word2Vec cannot (except for \"unnaturally\").\n",
    "\n",
    "- Word2Vec → 1/5\n",
    "- FastText → 5/5\n",
    "\n",
    "**Mechanism:**\n",
    "FastText represents each word not only as a whole, but also as the sum of its subword n-grams (3–6 letters).\n",
    "For example, the word “teachable” has never been encountered in the corpus, but it contains the following n-grams:\n",
    "`<te, tea, teach, each, acha, chab, hab, able, ble>`\n",
    "Since the words “teach”, “teacher”, “teaching”, “able” are present in the corpus, FastText is able to construct a vector of “teachable” using the vectors of these n-grams.\n",
    "\n",
    "Word2Vec does not have such a mechanism and works only with words that it has seen during training."
   ],
   "id": "6f76959205d7d5b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2․ Rare Words Quality",
   "id": "f1756802cc522e8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:59:50.819042Z",
     "start_time": "2025-12-04T16:59:50.697016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rare_pairs = [\n",
    "    (\"unteachable\", \"teacher\"),\n",
    "    (\"recomputation\", \"computation\"),\n",
    "    (\"unnaturalness\", \"natural\")\n",
    "]\n",
    "\n",
    "print(\"Similarity between rare words (appear only once) and related common words\")\n",
    "print(\"=\" * 75)\n",
    "print(f\"{'Pair':<35} {'Word2Vec':<15} {'FastText':<15}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for rare, common in rare_pairs:\n",
    "    w2v_sim = word2vec_model.wv.similarity(rare, common)\n",
    "    ft_sim = fasttext_model.wv.similarity(rare, common)\n",
    "\n",
    "    print(f\"{rare} → {common:<15} {w2v_sim:.4f}         {ft_sim:.4f}\")\n",
    "\n",
    "print(\"-\" * 75)"
   ],
   "id": "243e90364afb5057",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between rare words (appear only once) and related common words\n",
      "===========================================================================\n",
      "Pair                                Word2Vec        FastText       \n",
      "---------------------------------------------------------------------------\n",
      "unteachable → teacher         0.4578         0.4512\n",
      "recomputation → computation     0.6005         0.9393\n",
      "unnaturalness → natural         0.3933         0.6870\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2․  Which model produces better similarity scores for rare words? Why\n",
    "does FastText handle rare words better than Word2Vec?\n",
    "\n",
    "**Answer:**\n",
    "FastText gives significantly better similarity scores for rare words, even when they occur only once in the corpus.\n",
    "\n",
    "The difference is especially visible in the pairs \"recomputation\" and \"unnaturalness\": FastText gives 0.94 and 0.69 (very high and meaningful), and Word2Vec - 0.60 and 0.39 (low and less meaningful).\n",
    "\n",
    "**Why does FastText work better with rare words?**\n",
    "Since rare words (e.g., recomputation, unnaturalness) only occur once, Word2Vec sees very little context and their vectors are almost random.\n",
    "FastText, however, uses subword n-grams.\n",
    "- \"recomputation\" → contains \"computation\", \"compute\", \"reco\", \"puta\", etc.\n",
    "- \"unnaturalness\" → contains \"natural\", \"nature\", \"unnatural\", \"ness\"\n",
    "\n",
    "These n-grams occur a lot in the corpus, so FastText is able to \"recognize\" the morphological structure of the word and give a much more accurate vector.\n"
   ],
   "id": "24861770dee10ca7",
   "attachments": {
    "3d4f9abc-d2db-4af0-86ef-a025df92e112.png": {
     "image/png": "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"
    }
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.  Morphological Relationships",
   "id": "137e487d6d1f71b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T17:04:34.303834Z",
     "start_time": "2025-12-04T17:04:33.729784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Experiment 3: Morphological Relationships\n",
    "\n",
    "print(\"Top 5 most similar words for 'teaching'\\n\")\n",
    "print(\"Word2Vec →\", [w[0] for w in word2vec_model.wv.most_similar('teaching', topn=5)])\n",
    "print(\"FastText  →\", [w[0] for w in fasttext_model.wv.most_similar('teaching', topn=5)])\n",
    "\n",
    "print(\"\\n\" + \"═\" * 80 + \"\\n\")\n",
    "\n",
    "print(\"Top 5 most similar words for 'computation'\\n\")\n",
    "print(\"Word2Vec →\", [w[0] for w in word2vec_model.wv.most_similar('computation', topn=5)])\n",
    "print(\"FastText  →\", [w[0] for w in fasttext_model.wv.most_similar('computation', topn=5)])"
   ],
   "id": "ab8ee45851f0dfd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar words for 'teaching'\n",
      "\n",
      "Word2Vec → ['Considerable', 'marketable', 'pathology', 'self-discipline', 'home-owners']\n",
      "FastText  → ['Teaching', 'Bleaching', 'Reaching', 'sky-reaching', 'aching']\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Top 5 most similar words for 'computation'\n",
      "\n",
      "Word2Vec → ['1040', 'subcontracting', 'subsidies', \"BTU's\", 'inoculations']\n",
      "FastText  → ['recomputation', 'compilation', 'commutation', 'Computation', 'co-optation']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Does FastText group morphologically related words better? Provide specific examples from your results.\n",
    "\n",
    "**Answer:**\n",
    " Yes, FastText is significantly better at grouping morphologically related words than Word2Vec.\n",
    "\n",
    "FastText, thanks to subword n-grams (3–6 letters), “understands” the suffixes and prefixes of words (-ing, -tion, re-, un-, etc.) and based on them groups morphologically related words even in small corpuses.\n",
    "Word2Vec does not have this mechanism and gives almost random results.\n"
   ],
   "id": "a0e1f3b5b8e84370"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Word Analogies",
   "id": "9dfefe97d81811b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T17:07:50.454007Z",
     "start_time": "2025-12-04T17:07:50.339890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"1) teacher : teaching :: computer : ?   (expected: computing / computation)\\n\")\n",
    "w2v1 = word2vec_model.wv.most_similar(positive=['teaching', 'computer'], negative=['teacher'], topn=5)\n",
    "ft1 = fasttext_model.wv.most_similar(positive=['teaching', 'computer'], negative=['teacher'], topn=5)\n",
    "print(\"Word2Vec top 5 →\", [w[0] for w in w2v1])\n",
    "print(\"FastText  top 5 →\", [w[0] for w in ft1])\n",
    "\n",
    "print(\"\\n\" + \"═\" * 90 + \"\\n\")\n",
    "\n",
    "print(\"2) natural : naturally :: quick : ?   (expected: quickly)\\n\")\n",
    "w2v2 = word2vec_model.wv.most_similar(positive=['naturally', 'quick'], negative=['natural'], topn=5)\n",
    "ft2 = fasttext_model.wv.most_similar(positive=['naturally', 'quick'], negative=['natural'], topn=5)\n",
    "print(\"Word2Vec top 5 →\", [w[0] for w in w2v2])\n",
    "print(\"FastText  top 5 →\", [w[0] for w in ft2])"
   ],
   "id": "e4a40ef6801d5ea4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) teacher : teaching :: computer : ?   (expected: computing / computation)\n",
      "\n",
      "Word2Vec top 5 → ['lookup', 'glossary', 'form-dictionary', 'text-form', 'glottochronological']\n",
      "FastText  top 5 → ['computing', 'compiling', 'complying', 'compute', 'computes']\n",
      "\n",
      "══════════════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "2) natural : naturally :: quick : ?   (expected: quickly)\n",
      "\n",
      "Word2Vec top 5 → ['spontaneously', 'dubious', 'typing', 'unfavorable', \"Freddy's\"]\n",
      "FastText  top 5 → ['quickly', 'quickie', 'quickstep', 'wobbly', 'quiz']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Which model performs better on morphological analogies? Explain why.\n",
    "**Answer**\n",
    "- Word2Vec fails to find morphological patterns at all (-ing, -ly, etc.) and produces almost random words.\n",
    "- FastText ranks the correct answer **1st** in both analogies.\n",
    "\n",
    "**Why?**\n",
    "FastText learns vectors of subword n-grams (3–6 letters), so it “understands” that\n",
    "- teaching – teacher = +ing\n",
    "- naturally – natural = +ly\n",
    "and is able to apply that pattern to new words (computer → computing, quick → quickly).\n",
    "Word2Vec does not have such subword information and cannot generalize morphological changes."
   ],
   "id": "5feda58bb4013b4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
